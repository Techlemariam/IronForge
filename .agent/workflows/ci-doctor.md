---
description: "Comprehensive CI failure prevention and resolution"
command: "/ci-doctor"
category: "maintenance"
trigger: "manual"
version: "1.0.0"
telemetry: "enabled"
primary_agent: "@infrastructure"
domain: "ci"
---

# ü©∫ CI Doctor

**Role:** CI Health Specialist  
**Goal:** Prevent and cure CI failures with minimal iterations  
**Rating:** 10/10 (Full implementation with Docker simulation, auto-classification, and flakiness tracking)

---

## Phase 0: Pre-Flight (MANDATORY before ANY push)

### 0.0 Permission Hygiene

// turbo

```bash
# Ensure config.json is present to minimize permission interruptions
if [ ! -f ".agent/config.json" ]; then
  echo "‚ö†Ô∏è Warning: .agent/config.json missing. You may face frequent permission prompts."
else
  echo "‚úÖ Permissions: Configured"
fi
```

### 0.1 Dependency Check

// turbo

```bash
echo "üîç Checking dependency integrity..."
if ! git diff --quiet package-lock.json; then
  echo "‚õî ERROR: package-lock.json is dirty. running 'npm ci' required."
  exit 1
fi
echo "‚úÖ Dependencies: Clean"
```

### 0.2 Branch Validation

// turbo

```bash
current_branch=$(git rev-parse --abbrev-ref HEAD)

if [ "$current_branch" = "main" ]; then
  echo "‚õî ERROR: Cannot push to main. Use /claim-task"
  exit 1
fi

echo "‚úÖ Branch: $current_branch"
```

### 0.3 The Triple Gate

// turbo

```bash
echo "üîç Gate 1: Type Safety"
npm run check-types || exit 1

echo "üîç Gate 2: Linting"
npm run lint || exit 1

echo "üîç Gate 3: Unit Tests"
npm test || exit 1

echo "‚úÖ All gates passed"
```

### 0.4 Mock Validation

// turbo

```bash
echo "üîç Validating mock registry..."
npx ts-node scripts/validate-mocks.ts
```

### 0.5 E2E Stress Test (CI Simulation)

```bash
# Option A: Native (faster but less accurate)
npx playwright test tests/e2e/<target>.spec.ts --workers=1 --retries=0

# Option B: Docker (slower but matches CI exactly)
docker run --rm -v $(pwd):/work -w /work \
  mcr.microsoft.com/playwright:v1.40.0-jammy \
  npx playwright test tests/e2e/<target>.spec.ts --workers=1
```

> [!IMPORTANT]
> If Phase 0.5 fails, **DO NOT PUSH**. Proceed to Phase 1.

---

## Phase 1: Failure Classification

### 1.0 Automated Classification

// turbo

```bash
# If you have failure logs, run:
npx ts-node scripts/ci-classifier.ts ./ci-failure.log
```

### 1.1 Manual Classification Table

| Symptom | Category | Solution Section |
|:--------|:---------|:-----------------|
| `Timeout waiting for selector` | SELECTOR_TIMEOUT | ‚Üí 1A |
| `Expected X, received Y` | ASSERTION_MISMATCH | ‚Üí 1B |
| `TypeError` / `ReferenceError` | CODE_ERROR | ‚Üí 1C |
| `net::ERR_` / `fetch failed` | NETWORK_HANG | ‚Üí 1D |
| Tests pass locally, fail in CI | RACE_CONDITION | ‚Üí 1E |
| `SyntaxError` / `Unexpected token` | SYNTAX_ERROR | ‚Üí 1F |
| 0 passed, 0 failed (Skipped) | SILENT_FAILURE | ‚Üí Check Deps / Timeout |

---

### 1A: Selector Timeout (12% of failures)

**Root Cause:** Element not found, behind overlay, or **missing data** (conditional rendering).

**Fix Pattern:**

```typescript
// Pattern 1: Robust Selectors & Overlays
const element = await page.waitForSelector('[data-testid="my-button"]', { timeout: 15000 });
await element.evaluate(el => (el as HTMLElement).click());

// Pattern 2: Data Injection (Conditional Rendering)
// If element depends on data (e.g. list items), inject mock data FIRST
await page.evaluate(() => {
  (window as any).__mockItems = [{ id: '1', name: 'Test Item' }];
});
```

**Checklist:**

- [ ] Add `data-testid` to target component
- [ ] Use `waitForSelector` instead of `getByText`
- [ ] Use `evaluate.click()` to bypass overlays
- [ ] **Data Check**: Does element require specific state/data? (Inject Mocks)
- [ ] Increase timeout to 15000ms for slow CI

---

### 1B: Assertion Mismatch (4% of failures)

**Root Cause:** Mock data doesn't match expected values.

**Fix Pattern:**

```typescript
// Check tests/mocks/registry.ts for correct mock shape
import { MOCK_REGISTRY } from '../mocks/registry';

// Ensure mock matches schema
const mockUser = {
  id: 'test-user',
  heroName: 'Tester', // Must match MOCK_REGISTRY.user.schema
};
```

---

### 1C: Code Error (4% of failures)

**Root Cause:** TypeScript/JavaScript errors missed by type checker.

**Fix Pattern:**

```bash
# Verify types
npm run check-types

# Check for runtime issues
npm run build
```

---

### 1D: Network Hang (4% of failures)

**Root Cause:** Unmocked Supabase/external API calls.

**Fix Pattern:**

```typescript
// In test beforeEach, mock ALL external services
await page.addInitScript(() => {
  (window as any).__mockSessions = []; // Mock CoOpService.listSessions
  (window as any).__mockUser = { id: 'test', heroName: 'Test' };
});
```

**Checklist:**

- [ ] All Supabase calls mocked
- [ ] All external API calls intercepted
- [ ] No real network requests in tests

---

### 1E: Race Condition (15% of failures - MOST COMMON)

**Root Cause:** Mocks injected after component mounts.

**Fix Pattern:**

```typescript
// ‚ùå BAD: Mocks injected AFTER navigation
await page.goto('/dashboard');
await page.evaluate(() => { (window as any).__mockUser = {...} });

// ‚úÖ GOOD: Mocks injected BEFORE navigation
await page.addInitScript(() => { (window as any).__mockUser = {...} });
await page.goto('/dashboard');
```

**Hook Pattern:**

```typescript
// ‚ùå BAD: Async mock check in useEffect
useEffect(() => {
  if (window.__mockUser) setUser(window.__mockUser);
}, []);

// ‚úÖ GOOD: Sync mock check in useState initializer (lazy init)
const [user, setUser] = useState(() => {
  if (typeof window !== 'undefined' && (window as any).__mockUser) {
    return (window as any).__mockUser;
  }
  return null;
});
```

---

### 1F: Syntax Error (4% of failures)

**Root Cause:** Linting not run before push.

**Fix Pattern:**

```bash
npm run lint --fix
```

---

## Phase 2: The Repair Loop

**ITERATION LIMIT: 3**

```bash
ITERATION=0
MAX_ITERATIONS=3

while [ $ITERATION -lt $MAX_ITERATIONS ]; do
  echo "üîß Iteration $((ITERATION + 1)) of $MAX_ITERATIONS"
  
  # Apply fix based on Phase 1 classification
  # ... make code changes ...
  
  # STRATEGY SELECTION
  if [ $ITERATION -ge 1 ]; then
    echo "‚ö†Ô∏è Iteration 2+ detected: Switching to DOCKER simulation"
    # Use Docker to match CI environment exactly
    docker run --rm -v $(pwd):/work -w /work mcr.microsoft.com/playwright:v1.40.0-jammy \
      npx playwright test tests/e2e/<target>.spec.ts --workers=1
  else
    # First attempt: Native local test
    # REQUIREMENT: Run the FULL FILE to detect cascading failures in skipped tests
    echo "üß™ Running FULL file verification (No -g filter)..."
    npx playwright test tests/e2e/<target>.spec.ts --workers=1 --retries=0
  fi
  
  if [ $? -eq 0 ]; then
    echo "‚úÖ Tests pass. Safe to push."
    break
  fi
  
  ITERATION=$((ITERATION + 1))
done

if [ $ITERATION -eq $MAX_ITERATIONS ]; then
  echo "‚ö†Ô∏è ESCALATION REQUIRED: 3 iterations exhausted"
  echo "‚Üí Action 1: Quarantine the test in tests/flaky-tests.json"
  echo "‚Üí Action 2: Run /architect for structural review"
  exit 1
fi
```

---

## Phase 3: CI Monitoring

### 3.1 Push and Monitor

```bash
# Push changes
git push origin $(git branch --show-current)

# Wait for CI to register
sleep 5

# Get run ID for "IronForge CI/CD" workflow specifically
RUN_ID=$(gh run list --branch $(git branch --show-current) --limit 5 --json databaseId,workflowName --jq '.[] | select(.workflowName == "IronForge CI/CD") | .databaseId' | head -n 1)

if [ -z "$RUN_ID" ]; then
  echo "‚ö†Ô∏è Could not find specific CI run. Falling back to latest."
  RUN_ID=$(gh run list --branch $(git branch --show-current) --limit 1 --json databaseId -q '.[0].databaseId')
fi

echo "üì° Monitoring Run: $RUN_ID"
echo "üîó https://github.com/Techlemariam/IronForge/actions/runs/$RUN_ID"

# Watch with 15-minute timeout
timeout 900 gh run watch $RUN_ID --exit-status
```

### 3.2 On Failure: Artifact Collection

```bash
if [ $? -ne 0 ]; then
  echo "‚ùå CI FAILED - Collecting artifacts..."
  
  # Download artifacts
  gh run download $RUN_ID -D ./ci-artifacts 2>/dev/null
  
  # Get failure logs (try specific failure first, then all logs if empty)
  LOGFILE="ci-failure-$(date +%Y%m%d-%H%M).log"
  gh run view $RUN_ID --log-failed > $LOGFILE
  
  if [ ! -s "$LOGFILE" ]; then
    echo "‚ö†Ô∏è Failure logs empty (possible silent failure). Fetching full logs..."
    gh run view $RUN_ID --log > $LOGFILE
  fi
  
  echo "üìÅ Artifacts: ./ci-artifacts"
  echo "üìÑ Logs: $LOGFILE"
  
  # Auto-classify
  echo "üîç Auto-classifying error..."
  npx ts-node scripts/ci-classifier.ts $LOGFILE
  
  # Open trace if available
  if ls ./ci-artifacts/*/trace.zip 1>/dev/null 2>&1; then
    echo "üé≠ Opening Playwright trace..."
    npx playwright show-trace ./ci-artifacts/*/trace.zip
  fi
fi
```

---

## Phase 4: Post-Mortem

After successful CI run:

1. **Clean Up**: Remove debug `console.log` statements
2. **Document**: Update `DEBT.md` if systemic issue found
3. **Track**: Update `tests/flaky-tests.json` if test was flaky
4. **Prevent**: Add regression test for the failure mode
5. **Squash**: Clean commit history before merge
6. **Heal**: Update this workflow (`.agent/workflows/ci-doctor.md`) with new findings

---

## Escalation Matrix

| Condition | Action |
|:----------|:-------|
| 3+ iterations on same issue | ‚Üí `/architect` for structural review |
| Mock confusion | ‚Üí Review `tests/mocks/registry.ts` |
| Network/Supabase issues | ‚Üí `/infrastructure` |
| Unknown persistence | ‚Üí Add more instrumentation, increase traces |
| CI env differs from local | ‚Üí Use Docker simulation (Phase 0.4 Option B) |

---

## Supporting Tools

| Tool | Purpose | Location |
|:-----|:--------|:---------|
| **Error Classifier** | Auto-detect failure category | `scripts/ci-classifier.ts` |
| **Mock Registry** | Central mock definitions | `tests/mocks/registry.ts` |
| **Mock Validator** | Verify mocks at runtime | `scripts/validate-mocks.ts` |
| **Flakiness Tracker** | Historical failure data | `tests/flaky-tests.json` |

---

## Version History

### 1.1.0 (2026-01-13)

- **Process**: Added mandatory "Heal" step to Post-Mortem (Phase 4).
- **Protocol**: Workflows must now be updated with every new learning.

### 1.0.1 (2026-01-13)

- **Self-Healing**: Added "Data Injection" pattern to Phase 1A (Selector Timeout) after Run 31 analysis.
- **Refinement**: Clarified "Silent Failure" checks in Phase 1.1.

### 1.0.0 (2026-01-13)

- Initial release with 10/10 features
- Docker CI simulation
- Automated error classification
- Mock registry and validation
- Flakiness tracking
